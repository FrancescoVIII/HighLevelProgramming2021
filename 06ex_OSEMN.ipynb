{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import urllib.request\n",
    "import json \n",
    "import requests\n",
    "from bs4 import BeautifulSoup # Documentation: (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "import lxml.html as lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named \"data_int.txt\". Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named \"data_float.txt\". Use the `cat` command to print the content of the file.\n",
    "+ load the txt file of the previous point and convert it to a csv file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "[[8.24554513 9.3366494  8.71764772 5.58188511 4.13446655]\n",
      " [5.62383406 0.5802073  2.52420181 4.69640088 9.11729063]\n",
      " [9.2093432  9.73867043 1.60392928 5.662468   0.88034334]\n",
      " [3.50377543 6.59500255 5.14418725 6.91187067 8.80381572]\n",
      " [3.24685456 1.5594443  2.57914776 7.45340438 3.05167591]]\n"
     ]
    }
   ],
   "source": [
    "out_file_int = \"data/data_int.txt\"\n",
    "list_int = [1,2,3,4,5,6]\n",
    "with open(out_file_int, 'a') as outfile:\n",
    "    outfile.write(str(list_int)) \n",
    "    \n",
    "#!cat data/data_int.txt  --> This is the command cat for unix users\n",
    "!type data\\\"data_int.txt\" \n",
    "\n",
    "    \n",
    "out_file_float = \"data/data_float.txt\"\n",
    "#I create a random matrix of float from 0.5 to 10\n",
    "matrix_float = np.random.uniform(low=0.5, high=10, size=25).reshape((5,5))\n",
    "with open(out_file_float, 'a') as outfile:\n",
    "    outfile.write(str(matrix_float)) \n",
    "\n",
    "!type data\\\"data_float.txt\" \n",
    "    \n",
    "read_file = pd.read_csv(r'data\\data_float.txt')\n",
    "read_file.to_csv(r'data\\data_float.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------The following code is not the correct answare, I need to find a way to read the file directlu with the url\n",
    "#file = 'data/user_data.json'\n",
    "#f = open(file)\n",
    "#data = json.load(f)\n",
    "#------\n",
    "\n",
    "# Using the original url, the response of urllib is not sufficient to achieve the data since the page is not a simple\n",
    "# html page with the jSON data writed inside. The data are inside a different concatenate <div> tags, I have found an other url\n",
    "# in a iframe that link to the data, I have found it inspectioning the page with the browser.\n",
    "# Anyway the responce is still not ready to get the data with json.loads(), because there are still <span> tags between\n",
    "# (due to the html format), to delete them I have use the BeautifulSoup library. \n",
    "\n",
    "#url = 'https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json'\n",
    "url = 'https://uca9188014640b5b722d636dc70f.previews.dropboxusercontent.com/p/html_desktop/ABW4_k6RkSUfe-pjCZV_f3zLL9_DHzG0gIWsvqWhdzw1BL5XLXr818aSCaxYyeSjIVuhQMk7KdPQt3uAoaEczDYdrtBwXhKu_xOlQ_ShH9FQhbh5Ng3hGlnW3E98Kz9xQTjbaHgSvoO1Djdag1B89226Sz3JFc1jXRr6XQH_rKgYoBY8Au9nJsN9nhVG5iITbswmzXkWV0JXfRFglieLBhJo45IROWWXvbA0K87qjoU1CjDzCHHKZD_xMU7hSHoCGtovJWSNhOvqjs3PN30d14UpKuh_lhSkON90puD5hPaeJoECHhgCQ3VeKC25bb36Efy2rTn8ETPSeIGCvYH2PUepg1LG9Nobu1I72KVgAhgvsdQ_5p0N6NBBsNIJo06ceSs/p.html'\n",
    "\n",
    "#Extract the songtext only and save it in file\n",
    "text = urllib.request.urlopen(url)\n",
    "\n",
    "content = text.read()\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "#print(soup)\n",
    "\n",
    "#search on page for div class block songbook and extract songtext between <p>\n",
    "table = soup.find_all('span')\n",
    "JSONtext = \"\"\n",
    "for item in table:\n",
    "    JSONtext += item.text\n",
    "    \n",
    "\n",
    "dt_json = json.loads(JSONtext)\n",
    "        \n",
    "filtered_data = [x for x in dt_json if (x['CreditCardType'] == 'American Express')]\n",
    "read_file = pd.DataFrame(filtered_data)\n",
    "read_file.to_csv (r'data\\filtered_CSV.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------The following code is not the correct answare, I need to find a way to read the file directlu with the url\n",
    "#df = pd.read_csv(\"data/mushrooms_categorized.csv\")\n",
    "#------\n",
    "\n",
    "\n",
    "#url_csv = \"https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\"\n",
    "url_csv ='https://uc6a497ac8793aba0ba60392212b.previews.dropboxusercontent.com/p/html_desktop/ABXjeuEESJTIDjmRX_e9B2PFTE0x0ZJEd9_rmU5_7WKV_rs3qLnCqNiKocAxdX_PigxMjXsRCptD64nsFrev8B3XyfXOEYFkp9qb0eGR8FpzDgtjPGWZi5DcbofnMgmDBAiW8bJLm_Ymre6mj0GD2GvzNy_1wnmfy8EQHiLqp27JHW7hPzhJtQ0cBNCOHdUFO5rIim3Mo9N9hXX4PMMlBX6ZRSg8_JevKpw7rOEHxZRRWXATwe5K4A9Ta4Mz7NqQeB7-RmRp_AdD5dnv2z_d59ZPrH29G_ahuMuXe2VuZ-tVxkwo4v49egMG1dMqiWrhaHN3EPoyqxiCiJCtvNu0xaIbxtAtKWjXZ_FVAzanIOZ6FOp7TJa49R8hzLp2FYN7_p4/p.html'\n",
    "\n",
    "\n",
    "page = requests.get(url_csv)\n",
    "\n",
    "#Store the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "#Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')\n",
    "\n",
    "#Create empty list\n",
    "col=[]\n",
    "i=-1\n",
    "#For each row, store each first element (header) and an empty list\n",
    "for t in tr_elements[1]:\n",
    "    i+=1\n",
    "    if(i != 0):\n",
    "        name=t.text_content()\n",
    "        col.append((name,[]))\n",
    "        \n",
    "    \n",
    "#Since out first row is the header, data is stored on the second row onwards\n",
    "for j in range(2,len(tr_elements)):\n",
    "    \n",
    "    i=-1\n",
    "    \n",
    "    #Iterate through each element of the row\n",
    "    for t in tr_elements[j]:\n",
    "        dt = int(t.text_content())\n",
    "    \n",
    "        #Append the data to the empty list of the i'th column\n",
    "        if (i != -1):\n",
    "            col[i][1].append(dt)\n",
    "            #Increment i for the next column\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "Dict={title:column for (title,column) in col}\n",
    "\n",
    "df = pd.DataFrame(Dict)\n",
    "gr_class = df.groupby('class').mean()\n",
    "\n",
    "\n",
    "gr_class = df.groupby('class').mean()\n",
    "gr_class.to_json (r'data\\Average_feature_JSON.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072 - 8016 - 6118 - 5514\n",
      "6581 - 2571 - 6687 - 5500\n",
      "5155 - 3334 - 7344 - 0085\n",
      "3004 - 6306 - 6175 - 6483\n",
      "3765 - 4032 - 4705 - 7175\n",
      "8251 - 5351 - 2128 - 1636\n",
      "8117 - 2852 - 5321 - 4441\n",
      "2473 - 4543 - 0685 - 5278\n",
      "8107 - 4466 - 1634 - 1433\n",
      "0780 - 4161 - 7450 - 0150\n",
      "4552 - 2064 - 1625 - 3333\n",
      "1384 - 3403 - 8617 - 6400\n",
      "3042 - 6821 - 4063 - 0610\n",
      "4878 - 8787 - 1777 - 8060\n",
      "0168 - 6440 - 6535 - 0267\n",
      "1521 - 8344 - 4871 - 2746\n",
      "1366 - 5031 - 6652 - 7533\n",
      "5802 - 8577 - 4217 - 8357\n",
      "4027 - 5586 - 1813 - 1442\n",
      "3015 - 5810 - 3818 - 0064\n",
      "0665 - 2686 - 2121 - 4673\n",
      "4246 - 6604 - 4418 - 7544\n",
      "5711 - 0783 - 2273 - 5602\n",
      "8845 - 6838 - 5806 - 4650\n",
      "6326 - 1225 - 3054 - 3358\n",
      "7854 - 8472 - 2378 - 3667\n",
      "1806 - 6087 - 2146 - 8121\n",
      "2657 - 5007 - 3710 - 8804\n",
      "3808 - 5837 - 1402 - 6843\n",
      "8431 - 8831 - 4101 - 3162\n",
      "5705 - 4254 - 5772 - 4776\n",
      "5122 - 3062 - 0204 - 0887\n",
      "8284 - 8216 - 8717 - 3871\n",
      "3013 - 4337 - 7346 - 5088\n",
      "8217 - 8830 - 6372 - 3230\n",
      "5238 - 8734 - 2705 - 4503\n",
      "8326 - 2730 - 0643 - 4205\n",
      "4310 - 4778 - 6346 - 5500\n",
      "2773 - 7237 - 7277 - 8511\n",
      "7182 - 0474 - 3020 - 4621\n",
      "1820 - 3018 - 3648 - 5802\n",
      "5877 - 4582 - 1765 - 8408\n",
      "6717 - 8356 - 7767 - 8050\n",
      "4743 - 3513 - 3767 - 8320\n",
      "1648 - 7770 - 4437 - 7548\n",
      "3557 - 1175 - 2633 - 3500\n",
      "3413 - 5133 - 6478 - 3073\n",
      "5330 - 5761 - 2387 - 4033\n",
      "2475 - 7388 - 4110 - 3350\n",
      "6350 - 1623 - 4574 - 4327\n",
      "STOP\n"
     ]
    }
   ],
   "source": [
    "dat_file = r\"data\\credit_card.dat\"   \n",
    "\n",
    "CHUNK_SIZE = 6\n",
    "for_count = 0  \n",
    "Card_number = \"\"\n",
    "with open(dat_file) as f:\n",
    "    chunk = True\n",
    "    while chunk:\n",
    "        for i in range(4):\n",
    "            CHUNK_SIZE = 6\n",
    "            chunk = f.read(CHUNK_SIZE)\n",
    "            try:\n",
    "                num = int(chunk, 2)\n",
    "                Card_number += str(num%9)\n",
    "            except ValueError:\n",
    "                print(\"STOP\")\n",
    "                break\n",
    "        for_count += 1\n",
    "        if(for_count == 4):\n",
    "            for_count = 0\n",
    "            CHUNK_SIZE = 5\n",
    "            chunk = f.read(CHUNK_SIZE)\n",
    "            print(Card_number)\n",
    "            Card_number = \"\"\n",
    "        else:\n",
    "            chunk = f.read(CHUNK_SIZE)\n",
    "            Card_number += \" - \"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Optional**: load the remote file:\n",
    "\n",
    "- https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "\n",
    "with Pandas and create a scatter plot with all possible combinations of the following features:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
